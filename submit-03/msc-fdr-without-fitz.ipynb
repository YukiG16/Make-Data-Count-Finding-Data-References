{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82370,"databundleVersionId":13015230,"sourceType":"competition"},{"sourceId":248118764,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Original Notebook:\n\nhttps://www.kaggle.com/code/mccocoful/notebook2d0b45c244","metadata":{}},{"cell_type":"code","source":"! uv pip install -q --system --no-index --find-links='/kaggle/input/latest-mdc-whls/whls' 'pymupdf'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:45.657988Z","iopub.execute_input":"2025-07-18T05:44:45.658181Z","iopub.status.idle":"2025-07-18T05:44:46.656665Z","shell.execute_reply.started":"2025-07-18T05:44:45.658162Z","shell.execute_reply":"2025-07-18T05:44:46.655478Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"! mkdir src","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:46.657851Z","iopub.execute_input":"2025-07-18T05:44:46.658217Z","iopub.status.idle":"2025-07-18T05:44:46.780017Z","shell.execute_reply.started":"2025-07-18T05:44:46.658181Z","shell.execute_reply":"2025-07-18T05:44:46.778750Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%writefile src/common.py\nimport os\nimport polars as pl\n\nfrom pathlib import Path\nfrom typing import Tuple\n\nDOI_URL = 'https://doi.org/'\n\ndef is_submission(): return bool(os.getenv('KAGGLE_IS_COMPETITION_RERUN'))\ndef is_kaggle_env(): return (len([k for k in os.environ.keys() if 'KAGGLE' in k]) > 0) or is_submission()\n\ndef get_prefix_path(prefix: str)->Path:\n    return Path(f'/kaggle/{prefix}' if is_kaggle_env() else f'.{prefix}').expanduser().resolve()\n\ndef is_doi(name:str)->pl.Expr: return pl.col(name).str.starts_with(DOI_URL)\n\ndef doi_link_to_id(name:str)->pl.Expr:\n    return pl.when(is_doi(name)).then(pl.col(name).str.split(DOI_URL).list.last()).otherwise(name).alias(name)\n\ndef doi_id_to_link(name:str, substring:str, url:str=DOI_URL)->pl.Expr:\n    return pl.when(pl.col(name).str.starts_with(substring)).then(url+pl.col(name).str.to_lowercase()).otherwise(name).alias(name)\n\ndef score(preds: pl.DataFrame, gt: pl.DataFrame, on: list = ['article_id', 'dataset_id'], verbose:bool=True) -> Tuple[float, float, float]:\n    if 'id' in preds.columns and 'dataset_id' not in preds.columns: preds = preds.rename({'id': 'dataset_id'})\n    hits = gt.join(preds, on=on)\n    tp = hits.height\n    fp = preds.height - tp\n    fn = gt.height - tp\n\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n\n    if verbose:\n        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n        print(f\"True Positives: {tp}, False Positives: {fp}, False Negatives: {fn}\")\n\n    return precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:46.782829Z","iopub.execute_input":"2025-07-18T05:44:46.783163Z","iopub.status.idle":"2025-07-18T05:44:46.791453Z","shell.execute_reply.started":"2025-07-18T05:44:46.783133Z","shell.execute_reply":"2025-07-18T05:44:46.790566Z"}},"outputs":[{"name":"stdout","text":"Writing src/common.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile src/parse.py\nimport argparse\nimport pymupdf\nimport pathlib\nimport tqdm\n\nfrom common import get_prefix_path, is_submission\n\ndef get_args():\n    p = argparse.ArgumentParser()\n    p.add_argument('-i', default=f'make-data-count-finding-data-references/{\"test\" if is_submission() else \"train\"}/PDF')\n    p.add_argument('-o', default='parsed')\n    return p.parse_args()\n\ndef pdf2text(path: pathlib.Path, out_dir: pathlib.Path) -> None:\n    doc = pymupdf.open(str(path))\n    out = open(out_dir / f\"{path.stem}.txt\", \"wb\")\n    for page in doc:\n        text = page.get_text().encode(\"utf8\")\n        out.write(text)\n        out.write(b'\\n') # write page delimiter (form feed 0x0C)\n    out.close()\n\ndef main():\n    args = get_args()\n    in_dir = get_prefix_path('input') / args.i\n    out_dir = get_prefix_path('working') / args.o\n\n    if out_dir.exists() and any(out_dir.iterdir()):\n        print(f'{out_dir} already populated, skipping...')\n        return\n\n    out_dir.mkdir(parents=True, exist_ok=True)\n    if not in_dir.is_dir(): raise ValueError(f'{in_dir} is not a directory...')\n    pdf_files = list(in_dir.glob('*.pdf'))\n    if not pdf_files: raise ValueError(f'No PDF files found in {in_dir}')\n\n    for pdf in tqdm.tqdm(pdf_files, desc=\"Processing PDFs\"): pdf2text(pdf, out_dir)\n    print('ending parsing...')\n\nif __name__ == '__main__': main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:46.795717Z","iopub.execute_input":"2025-07-18T05:44:46.796051Z","iopub.status.idle":"2025-07-18T05:44:46.809280Z","shell.execute_reply.started":"2025-07-18T05:44:46.796007Z","shell.execute_reply":"2025-07-18T05:44:46.808323Z"}},"outputs":[{"name":"stdout","text":"Writing src/parse.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile src/getacc.py\nimport polars as pl\nimport argparse\nimport pathlib\nfrom common import score, get_prefix_path, is_submission, is_doi, doi_id_to_link\n\ndef get_args():\n    p = argparse.ArgumentParser()\n    p.add_argument('-i', default='parsed')\n    p.add_argument('-o', default='extracted_ids.parquet')\n    p.add_argument('--gt', default='make-data-count-finding-data-references/train_labels.csv')\n    p.add_argument('--ws', default=100, type=int)\n    return p.parse_args()\n\ndef get_text_df(parsed_dir: pathlib.Path):\n    paths = list(parsed_dir.rglob('*.txt'))\n    records = [{'article_id': p.stem, 'text': p.read_text()} for p in paths]\n    return (\n        pl.DataFrame(records)\n        .with_columns(pl.col(\"text\").str.normalize(\"NFKC\").str.replace_all(r\"[^\\p{Ascii}]\", \"\"))\n        .with_columns(pl.col('text').str.split(r'\\n{2,}').list.eval(pl.col(\"\").str.replace_all('\\n', ' ')).list.join('\\n').alias('text'))\n        .with_columns([\n            pl.col(\"text\").str.slice(pl.col(\"text\").str.len_chars()//4).str.reverse().alias('rtext'),\n            pl.col(\"text\").str.slice(0, pl.col(\"text\").str.len_chars()//4).alias('ltext'),\n        ])\n        .with_columns(pl.col('rtext').str.find(r'(?i)\\b(secnerefer|erutaretil detic|stnemegdelwonkca)\\b').alias('ref_idx'))\n        .with_columns(pl.when(pl.col('ref_idx').is_null()).then(0).otherwise('ref_idx').alias('ref_idx'))\n        .with_columns([\n            pl.col('rtext').str.slice(0, pl.col('ref_idx')).str.reverse().alias('refs'),\n            (pl.col('ltext') + pl.col('rtext').str.slice(pl.col('ref_idx')).str.reverse()).alias('body')\n        ])\n        .drop('rtext', 'ltext')\n    )\n\n\ndef main():\n    print('starting extraction of accession ids')\n    args = get_args()\n    in_path, out_path = map(lambda x: get_prefix_path('working') / x, (args.i, args.o))\n    text_df = get_text_df(in_path)\n\n    df = (\n        text_df\n        .with_columns([\n            pl.col(\"text\").str.extract_all(r'(?i)\\b(?:CHEMBL\\d+|E-GEOD-\\d+|E-PROT-\\d+|EMPIAR-\\d+|ENSBTAG\\d+|ENSOARG\\d+|EPI_ISL_\\d{5,}|EPI\\d{6,7}|HPA\\d+|CP\\d{6}|IPR\\d{6}|PF\\d{5}|KX\\d{6}|K0\\d{4}|PRJNA\\d+|PXD\\d+|SAMN\\d+|dryad\\.[^\\s\"<>]+|pasta\\/[^\\s\"<>])').alias('id'),\n        ])\n        .explode('id')\n        .with_columns(pl.col('id').alias('match_id'))\n        .with_columns(pl.col('id').str.replace_all(r'\\s', ''))\n        .with_columns(pl.col('id').str.replace(r'[-.,;:!?\\/\\)\\]\\(\\[]+$', ''))\n        .with_columns(doi_id_to_link(name='id', substring='dryad.', url='https://doi.org/10.5061/'))\n        .with_columns(doi_id_to_link(name='id', substring='pasta/', url='https://doi.org/10.6073/'))\n        .filter(~pl.col('id').str.to_lowercase().str.contains(pl.col('article_id').str.to_lowercase().str.replace('_', '/')))\n        .filter(~pl.col('id').str.contains('figshare', literal=True))\n        .filter(pl.when(is_doi('id').and_(pl.col('id').str.split('/').list.last().str.len_chars()<4)).then(pl.lit(False)).otherwise(pl.lit(True)))\n        .filter(~pl.col('id').is_in(['https://doi.org/10.5061/dryad', 'https://doi.org/10.6073/pasta', 'https://doi.org/10.5281/zenodo']))\n        .filter(pl.col('id').str.count_matches(r'\\(') == pl.col('id').str.count_matches(r'\\)'))\n        .filter(pl.col('id').str.count_matches(r'\\[') == pl.col('id').str.count_matches(r'\\]'))\n        .with_columns(\n            pl.col('text').str.slice(pl.col('text').str.find(pl.col('match_id'), literal=True)-args.ws-pl.col('match_id').str.len_chars(), 2*(args.ws+pl.col('match_id').str.len_chars())).alias('window')\n        )\n        .unique(['article_id', 'id'])\n        .rename({'id': 'dataset_id'})\n    )\n    df.select('article_id', 'dataset_id', 'window').write_parquet(out_path)\n    print(f'id extraction written to {out_path}')\n\n    df = df.select('article_id', 'dataset_id').with_columns(pl.lit('Secondary').alias('type'))\n    df = df.with_columns(\n        pl.when(is_doi('dataset_id').or_(pl.col('dataset_id').str.starts_with('SAMN'))).then(pl.lit('Primary')).otherwise('type').alias('type')\n    )\n\n    df.with_row_index(name='row_id').write_csv(get_prefix_path('working')/'submission.csv')\n\n    if not is_submission():\n        gt_path = get_prefix_path('input') / args.gt\n        gt = pl.read_csv(gt_path).filter(pl.col('type')!='Missing').join(text_df, on='article_id')\n        print('### DOI ###')\n        score(df.filter(is_doi('dataset_id')), gt.filter(is_doi('dataset_id')))\n        print('### ACC ###')\n        score(df.filter(~is_doi('dataset_id')), gt.filter(~is_doi('dataset_id')))\n        print('### ALL ###')\n        score(df, gt)\n        print('### TYPE ###')\n        score(df, gt, on=['article_id', 'dataset_id', 'type'])\n\nif __name__=='__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:46.810306Z","iopub.execute_input":"2025-07-18T05:44:46.810539Z","iopub.status.idle":"2025-07-18T05:44:46.829457Z","shell.execute_reply.started":"2025-07-18T05:44:46.810520Z","shell.execute_reply":"2025-07-18T05:44:46.828596Z"}},"outputs":[{"name":"stdout","text":"Writing src/getacc.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"! python src/parse.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:44:46.830664Z","iopub.execute_input":"2025-07-18T05:44:46.831112Z","iopub.status.idle":"2025-07-18T05:46:22.233041Z","shell.execute_reply.started":"2025-07-18T05:44:46.831071Z","shell.execute_reply":"2025-07-18T05:46:22.231860Z"}},"outputs":[{"name":"stdout","text":"Processing PDFs:  13%|███▏                     | 67/524 [00:10<01:46,  4.27it/s]MuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nProcessing PDFs: 100%|████████████████████████| 524/524 [01:33<00:00,  5.60it/s]\nending parsing...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"! python src/getacc.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:46:22.234482Z","iopub.execute_input":"2025-07-18T05:46:22.234818Z","iopub.status.idle":"2025-07-18T05:46:25.531806Z","shell.execute_reply.started":"2025-07-18T05:46:22.234784Z","shell.execute_reply":"2025-07-18T05:46:25.530954Z"}},"outputs":[{"name":"stdout","text":"starting extraction of accession ids\nid extraction written to /kaggle/working/extracted_ids.parquet\n### DOI ###\nPrecision: 0.9265, Recall: 0.1938, F1: 0.3206\nTrue Positives: 63, False Positives: 5, False Negatives: 262\n### ACC ###\nPrecision: 0.7188, Recall: 0.8046, F1: 0.7593\nTrue Positives: 317, False Positives: 124, False Negatives: 77\n### ALL ###\nPrecision: 0.7466, Recall: 0.5285, F1: 0.6189\nTrue Positives: 380, False Positives: 129, False Negatives: 339\n### TYPE ###\nPrecision: 0.6621, Recall: 0.4687, F1: 0.5489\nTrue Positives: 337, False Positives: 172, False Negatives: 382\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"! rm -rf parsed\n! rm -rf src\n! rm -rf extracted_ids.parquet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:46:25.534395Z","iopub.execute_input":"2025-07-18T05:46:25.534670Z","iopub.status.idle":"2025-07-18T05:46:25.898267Z","shell.execute_reply.started":"2025-07-18T05:46:25.534643Z","shell.execute_reply":"2025-07-18T05:46:25.897099Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Result: \n\nScore: 0.520\n\nRank: 75 (2025-07-18-15:12, JST)\n\nRun timme: 5min (kaggle editor), 15min (Scoring)\n\nYour Best Entry!\nYour most recent submission scored 0.520, which is an improvement of your previous score of 0.095. Great job!\n\nMoved up to rank 75 #kaggle https://kaggle.com/competitions/make-data-count-finding-data-references ","metadata":{}},{"cell_type":"markdown","source":"Make Data Count, Maggie Demkin, and Walter Reade. Make Data Count - Finding Data References. https://kaggle.com/competitions/make-data-count-finding-data-references, 2025. Kaggle.","metadata":{}}]}